{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c851a4d9-8a20-4001-850e-67ee8ccaa606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e367bf2-c03b-47ed-aac6-99c244934eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    LongformerTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab407b4f-de44-48aa-9dfd-76c51f6acd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': 'allenai/longformer-base-4096',\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c095aec-7fb4-4d6b-ab50-9d7f703cdaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7709473f-0d58-498d-a6f8-b64586033f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/evafs/groups/ganzha_23/mgalkowski/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for dair-ai/emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/dair-ai/emotion\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b428ba63534235bc100896e246e94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/592k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba79675b1754fecbdf99a403cc38f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/74.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92028184946c4663bcf3aa4b88a4d59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/74.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f97f39c06304b618d20315887e8617e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14883cd546a24c4fb23ede13c12cdec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd3b5a088dc47a39852cb5532bbf1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440f0bb698944ed4b05420afef2b9ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d234376898428dad6131f9e04cccd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb0ee9b3b4941fab2e652a68de11b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32771e5169e44f3d8f4fb6302ec68c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6c4916a1c1493c83625f5d9f398dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ef21c63f584885893a8c970f35fad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model_name = config[\"model_name\"]\n",
    "model_path = (\n",
    "    model_name.split(\"/\")[-1].replace(\"-\", \"_\") + \"_text_classification_emotion\" + \"_adamw\"\n",
    ")\n",
    "BATCH_SIZE = config[\"batch_size\"]\n",
    "NUM_EPOCHS = config[\"num_epochs\"]\n",
    "\n",
    "if os.path.exists('emotion'):\n",
    "    shutil.rmtree('emotion')\n",
    "\n",
    "emotion = load_dataset(\"dair-ai/emotion\", cache_dir='emotion')\n",
    "\n",
    "\n",
    "def filter_labels(example):\n",
    "    return example['label'] in [0, 1]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=max_length)\n",
    "\n",
    "train = emotion['train'].filter(filter_labels)\n",
    "valid = emotion['validation'].filter(filter_labels)\n",
    "test = emotion['test'].filter(filter_labels)\n",
    "\n",
    "tokenizer = LongformerTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenized_train = train.map(preprocess_function, batched=True, remove_columns=['text'])\n",
    "tokenized_valid = valid.map(preprocess_function, batched=True, remove_columns=['text'])\n",
    "tokenized_test = test.map(preprocess_function, batched=True, remove_columns=['text'])\n",
    "\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = config[\"model_name\"]\n",
    "# model_path = (\n",
    "#     model_name.split(\"/\")[-1].replace(\"-\", \"_\") + \"_text_classification_imdb\" + \"_adamw\"\n",
    "# )\n",
    "# BATCH_SIZE = config[\"batch_size\"]\n",
    "# NUM_EPOCHS = config[\"num_epochs\"]\n",
    "\n",
    "# if os.path.exists('model_path'):\n",
    "#     shutil.rmtree('model_path')\n",
    "\n",
    "# imdb = load_dataset(\"imdb\", cache_dir=\"model_path\")\n",
    "# imdb_train = imdb['train']\n",
    "# imdb_test = imdb['test']\n",
    "\n",
    "# tokenizer = LongformerTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# def preprocess_function(examples):\n",
    "#     return tokenizer(examples[\"text\"], truncation=True, max_length=max_length)\n",
    "\n",
    "# tokenized_imdb_train = imdb_train.map(preprocess_function, batched=True, remove_columns=['text'])\n",
    "# tokenized_imdb_test = imdb_test.map(preprocess_function, batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9902a541-1d82-4347-ab1a-ff93c8204a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "id2label = {\n",
    "    0: \"SADNESS\",\n",
    "    1: \"JOY\",\n",
    "}\n",
    "label2id = {v:k for k,v in id2label.items()}\n",
    "\n",
    "# id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "# label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f1f71d6-2a6a-4229-a104-62610b7305b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerConfig\n",
    "\n",
    "cfg = LongformerConfig.from_pretrained(model_name)\n",
    "cfg.attention_window = 64\n",
    "cfg.max_position_embeddings = 514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f588d6fc-8395-4de0-915e-c06e8d3f1434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "# label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "cfg.num_labels = 2\n",
    "cfg.id2label = id2label\n",
    "cfg.label2id = label2id\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "089d7975-bf11-4a83-b1b7-f2cad07262e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = deepcopy(control)\n",
    "            self._trainer.evaluate(\n",
    "                eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\"\n",
    "            )\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15d1829c-ee3e-4bc3-ad35-5c63170163d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5093347-3b31-4ef7-950f-bac8a8962f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 4863 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9a02d0a-e6a7-420f-a923-386cfa61c03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8149, 'grad_norm': 4.497572422027588, 'learning_rate': 1.9363057324840767e-05, 'epoch': 0.03184713375796178}\n",
      "{'loss': 0.6997, 'grad_norm': 1.9697051048278809, 'learning_rate': 1.872611464968153e-05, 'epoch': 0.06369426751592357}\n",
      "{'loss': 0.7084, 'grad_norm': 1.5512731075286865, 'learning_rate': 1.8089171974522295e-05, 'epoch': 0.09554140127388536}\n",
      "{'loss': 0.7106, 'grad_norm': 4.72462797164917, 'learning_rate': 1.7452229299363058e-05, 'epoch': 0.12738853503184713}\n",
      "{'loss': 0.7157, 'grad_norm': 1.624863862991333, 'learning_rate': 1.6815286624203824e-05, 'epoch': 0.1592356687898089}\n",
      "{'loss': 0.7065, 'grad_norm': 2.189979314804077, 'learning_rate': 1.617834394904459e-05, 'epoch': 0.1910828025477707}\n",
      "{'loss': 0.6868, 'grad_norm': 1.9691681861877441, 'learning_rate': 1.5541401273885352e-05, 'epoch': 0.2229299363057325}\n",
      "{'loss': 0.7118, 'grad_norm': 2.9706578254699707, 'learning_rate': 1.4904458598726114e-05, 'epoch': 0.25477707006369427}\n",
      "{'loss': 0.6955, 'grad_norm': 2.202850341796875, 'learning_rate': 1.426751592356688e-05, 'epoch': 0.28662420382165604}\n",
      "{'loss': 0.7005, 'grad_norm': 4.966599464416504, 'learning_rate': 1.3630573248407644e-05, 'epoch': 0.3184713375796178}\n",
      "{'loss': 0.7423, 'grad_norm': 3.0291903018951416, 'learning_rate': 1.2993630573248408e-05, 'epoch': 0.3503184713375796}\n",
      "{'loss': 0.7235, 'grad_norm': 2.92452335357666, 'learning_rate': 1.2356687898089172e-05, 'epoch': 0.3821656050955414}\n",
      "{'loss': 0.6901, 'grad_norm': 1.8872231245040894, 'learning_rate': 1.1719745222929938e-05, 'epoch': 0.4140127388535032}\n",
      "{'loss': 0.7036, 'grad_norm': 1.5126405954360962, 'learning_rate': 1.1082802547770702e-05, 'epoch': 0.445859872611465}\n",
      "{'loss': 0.6934, 'grad_norm': 3.386711597442627, 'learning_rate': 1.0445859872611466e-05, 'epoch': 0.47770700636942676}\n",
      "{'loss': 0.6885, 'grad_norm': 1.753171443939209, 'learning_rate': 9.80891719745223e-06, 'epoch': 0.5095541401273885}\n",
      "{'loss': 0.6995, 'grad_norm': 1.6323344707489014, 'learning_rate': 9.171974522292994e-06, 'epoch': 0.5414012738853503}\n",
      "{'loss': 0.7167, 'grad_norm': 1.6741584539413452, 'learning_rate': 8.53503184713376e-06, 'epoch': 0.5732484076433121}\n",
      "{'loss': 0.6832, 'grad_norm': 2.0528950691223145, 'learning_rate': 7.898089171974524e-06, 'epoch': 0.6050955414012739}\n",
      "{'loss': 0.7014, 'grad_norm': 3.8142781257629395, 'learning_rate': 7.261146496815287e-06, 'epoch': 0.6369426751592356}\n",
      "{'loss': 0.6829, 'grad_norm': 2.9130313396453857, 'learning_rate': 6.624203821656051e-06, 'epoch': 0.6687898089171974}\n",
      "{'loss': 0.6967, 'grad_norm': 5.266615390777588, 'learning_rate': 5.987261146496816e-06, 'epoch': 0.7006369426751592}\n",
      "{'loss': 0.695, 'grad_norm': 3.187962532043457, 'learning_rate': 5.35031847133758e-06, 'epoch': 0.732484076433121}\n",
      "{'loss': 0.6776, 'grad_norm': 1.4723584651947021, 'learning_rate': 4.713375796178344e-06, 'epoch': 0.7643312101910829}\n",
      "{'loss': 0.6872, 'grad_norm': 3.240784168243408, 'learning_rate': 4.076433121019109e-06, 'epoch': 0.7961783439490446}\n",
      "{'loss': 0.682, 'grad_norm': 3.9872875213623047, 'learning_rate': 3.4394904458598725e-06, 'epoch': 0.8280254777070064}\n",
      "{'loss': 0.6694, 'grad_norm': 4.973066806793213, 'learning_rate': 2.802547770700637e-06, 'epoch': 0.8598726114649682}\n",
      "{'loss': 0.6679, 'grad_norm': 3.16906476020813, 'learning_rate': 2.1656050955414015e-06, 'epoch': 0.89171974522293}\n",
      "{'loss': 0.6707, 'grad_norm': 1.7850909233093262, 'learning_rate': 1.5286624203821657e-06, 'epoch': 0.9235668789808917}\n",
      "{'loss': 0.6428, 'grad_norm': 5.29671573638916, 'learning_rate': 8.9171974522293e-07, 'epoch': 0.9554140127388535}\n",
      "{'loss': 0.6704, 'grad_norm': 1.912813663482666, 'learning_rate': 2.547770700636943e-07, 'epoch': 0.9872611464968153}\n",
      "{'train_loss': 0.6493573188781738, 'train_accuracy': 0.617271639409653, 'train_runtime': 14.5855, 'train_samples_per_second': 687.534, 'train_steps_per_second': 21.528, 'epoch': 1.0}\n",
      "{'eval_loss': 0.6602944731712341, 'eval_accuracy': 0.5917065390749602, 'eval_runtime': 1.9004, 'eval_samples_per_second': 659.867, 'eval_steps_per_second': 21.048, 'epoch': 1.0}\n",
      "{'train_runtime': 70.592, 'train_samples_per_second': 142.056, 'train_steps_per_second': 4.448, 'train_loss': 0.6973010840689301, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    logging_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    optim='adamw_torch',\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.add_callback(CustomCallback(trainer))\n",
    "\n",
    "result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58476055-7ecc-49af-b8db-a1c5ed87d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 70.59\n",
      "Samples/second: 142.06\n",
      "GPU memory occupied: 7795 MB.\n"
     ]
    }
   ],
   "source": [
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91866285-4324-4df6-a3da-6f34dc94a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [\n",
    "    {\n",
    "        k: v\n",
    "        for k, v in dictionary.items()\n",
    "        if k in (\"train_loss\", \"train_accuracy\", \"epoch\")\n",
    "    }\n",
    "    for dictionary in trainer.state.log_history\n",
    "    if \"train_accuracy\" in dictionary\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbec7fe9-5372-44a2-8a1b-ee20ddef116b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_loss': 0.6493573188781738,\n",
       "  'train_accuracy': 0.617271639409653,\n",
       "  'epoch': 1.0}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ae257a1-74e4-4ec1-aaa7-ef6f30dfc006",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [\n",
    "    {\n",
    "        k: v\n",
    "        for k, v in dictionary.items()\n",
    "        if k in (\"train_loss\", \"train_accuracy\", \"epoch\")\n",
    "    }\n",
    "    for dictionary in trainer.state.log_history\n",
    "    if \"train_accuracy\" in dictionary\n",
    "]\n",
    "train_losses = pd.DataFrame(train_losses)\n",
    "train_losses.epoch = train_losses.epoch.astype(int)\n",
    "\n",
    "val_losses = [\n",
    "    {\n",
    "        k: v\n",
    "        for k, v in dictionary.items()\n",
    "        if k in (\"eval_loss\", \"eval_accuracy\", \"epoch\")\n",
    "    }\n",
    "    for dictionary in trainer.state.log_history\n",
    "    if \"eval_accuracy\" in dictionary\n",
    "]\n",
    "val_losses = pd.DataFrame(val_losses)\n",
    "val_losses.epoch = val_losses.epoch.astype(int)\n",
    "\n",
    "# train_losses.to_csv(f\"checkpoints/{model_path}/train_losses.csv\", index=False)\n",
    "# val_losses.to_csv(f\"checkpoints/{model_path}/val_losses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b27e122-0f39-4f90-bd7d-8740380234c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.649357</td>\n",
       "      <td>0.617272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_accuracy  epoch\n",
       "0    0.649357        0.617272      1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5144546b-cca5-4bcc-8fae-b6d9392bf7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.660294</td>\n",
       "      <td>0.591707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_loss  eval_accuracy  epoch\n",
       "0   0.660294       0.591707      1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8804b234-5540-48c6-ab4e-e3f9463cb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = trainer.predict(tokenized_test)\n",
    "\n",
    "# with open(f\"checkpoints/{model_path}/test_metrics.json\", \"w\") as f:\n",
    "    # json.dump(output.metrics, f, indent=4)\n",
    "\n",
    "# with open(f\"checkpoints/{model_path}/config.json\", \"w\") as f:\n",
    "    # json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e4ec716-3e04-4a4d-8857-1930b0e5d810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.6605867743492126,\n",
       " 'test_accuracy': 0.5963949843260188,\n",
       " 'test_runtime': 2.2935,\n",
       " 'test_samples_per_second': 556.349,\n",
       " 'test_steps_per_second': 17.44}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf85f9-5cd3-4831-893f-d3beb77aea90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
